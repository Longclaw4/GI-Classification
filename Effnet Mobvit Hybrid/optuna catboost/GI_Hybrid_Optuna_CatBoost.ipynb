{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# GI Hybrid Model Optimization with Optuna TPE + CatBoost\n",
                "\n",
                "This notebook optimizes your trained hybrid model using:\n",
                "- **Optuna TPE**: Hyperparameter optimization\n",
                "- **CatBoost**: Meta-learner on top of hybrid features\n",
                "\n",
                "## Expected Improvement: 89.58% â†’ 91-93%\n",
                "\n",
                "## Setup:\n",
                "1. Enable GPU (Runtime â†’ Change runtime type â†’ T4 GPU)\n",
                "2. Upload your trained `hybrid_model_best.pth`\n",
                "3. Run all cells"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi\n",
                "\n",
                "import torch\n",
                "print(f\"\\nPyTorch GPU available: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Install Packages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q tensorflow>=2.16.0\n",
                "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
                "!pip install -q optuna catboost scikit-learn matplotlib seaborn pandas numpy\n",
                "\n",
                "print(\"âœ… All packages installed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Download Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import zipfile\n",
                "import ssl\n",
                "\n",
                "ssl._create_default_https_context = ssl._create_unverified_context\n",
                "\n",
                "if not os.path.exists(\"kvasir-dataset-v2\"):\n",
                "    print(\"Downloading Kvasir dataset...\")\n",
                "    !wget --no-check-certificate -q https://datasets.simula.no/downloads/kvasir/kvasir-dataset-v2.zip\n",
                "    \n",
                "    print(\"Extracting...\")\n",
                "    with zipfile.ZipFile(\"kvasir-dataset-v2.zip\", 'r') as zip_ref:\n",
                "        zip_ref.extractall(\".\")\n",
                "    os.remove(\"kvasir-dataset-v2.zip\")\n",
                "    print(\"âœ… Dataset ready!\")\n",
                "else:\n",
                "    print(\"âœ… Dataset already exists!\")\n",
                "\n",
                "data_dir = \"kvasir-dataset-v2/\"\n",
                "classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
                "print(f\"\\nFound {len(classes)} classes: {classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Upload Models from Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import shutil\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "DRIVE_FOLDER = \"/content/drive/MyDrive/GI_hybrid\"\n",
                "\n",
                "os.makedirs(\"mobvit\", exist_ok=True)\n",
                "os.makedirs(\"model_checkpoints\", exist_ok=True)\n",
                "\n",
                "# Copy files\n",
                "files_to_copy = [\n",
                "    (f\"{DRIVE_FOLDER}/model.py\", \"mobvit/model.py\"),\n",
                "    (f\"{DRIVE_FOLDER}/efficientnet_v2m_best_model.weights.h5\", \"model_checkpoints/efficientnet_v2m_best_model.weights.h5\"),\n",
                "    (f\"{DRIVE_FOLDER}/hybrid_model_best.pth\", \"hybrid_model_best.pth\"),\n",
                "]\n",
                "\n",
                "for src, dst in files_to_copy:\n",
                "    if os.path.exists(src):\n",
                "        shutil.copy(src, dst)\n",
                "        print(f\"âœ… Copied {os.path.basename(dst)}\")\n",
                "    else:\n",
                "        print(f\"âš ï¸ {os.path.basename(src)} not found\")\n",
                "\n",
                "print(\"\\nâœ… Files ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Load Models"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import tensorflow as tf\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "\n",
                "sys.path.append('./mobvit')\n",
                "from model import MobileViT\n",
                "\n",
                "# Create MobileViT\n",
                "def create_mobilevit(num_classes=8):\n",
                "    return MobileViT(\n",
                "        image_size=224,\n",
                "        num_classes=num_classes,\n",
                "        dims=[96, 192, 384],\n",
                "        channels=[16, 32, 64, 128, 160, 192, 256, 320, 384, 512],\n",
                "        depths=[2, 4, 3]\n",
                "    )\n",
                "\n",
                "# Create EfficientNet\n",
                "def create_efficientnet(num_classes=8):\n",
                "    base_model = tf.keras.applications.EfficientNetV2M(\n",
                "        input_shape=(224, 224, 3),\n",
                "        include_top=False,\n",
                "        weights=\"imagenet\"\n",
                "    )\n",
                "    base_model.trainable = True\n",
                "    \n",
                "    inputs = tf.keras.Input(shape=(224, 224, 3))\n",
                "    x = tf.keras.applications.efficientnet_v2.preprocess_input(inputs)\n",
                "    x = base_model(x, training=False)\n",
                "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
                "    x = tf.keras.layers.Dropout(0.2)(x)\n",
                "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
                "    \n",
                "    return tf.keras.Model(inputs, outputs)\n",
                "\n",
                "# Hybrid Model\n",
                "class HybridGIModel(nn.Module):\n",
                "    def __init__(self, num_classes=8):\n",
                "        super(HybridGIModel, self).__init__()\n",
                "        self.mobilevit = create_mobilevit(num_classes=num_classes)\n",
                "        self.fusion_weights = nn.Parameter(torch.tensor([0.5, 0.5]))\n",
                "        self.fusion_fc = nn.Sequential(\n",
                "            nn.Linear(num_classes * 2, 128),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(128, num_classes)\n",
                "        )\n",
                "        self.num_classes = num_classes\n",
                "        self.use_advanced_fusion = True\n",
                "    \n",
                "    def forward(self, x, efficientnet_logits=None, return_features=False):\n",
                "        mobilevit_logits = self.mobilevit(x)\n",
                "        \n",
                "        if efficientnet_logits is None:\n",
                "            return mobilevit_logits\n",
                "        \n",
                "        weights = F.softmax(self.fusion_weights, dim=0)\n",
                "        combined = torch.cat([mobilevit_logits, efficientnet_logits], dim=1)\n",
                "        \n",
                "        if return_features:\n",
                "            return combined  # Return concatenated features for CatBoost\n",
                "        \n",
                "        if self.use_advanced_fusion:\n",
                "            output = self.fusion_fc(combined)\n",
                "        else:\n",
                "            output = weights[0] * mobilevit_logits + weights[1] * efficientnet_logits\n",
                "        \n",
                "        return output\n",
                "\n",
                "# Load models\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "hybrid_model = HybridGIModel(num_classes=8).to(device)\n",
                "hybrid_model.load_state_dict(torch.load('hybrid_model_best.pth', map_location=device))\n",
                "hybrid_model.eval()\n",
                "\n",
                "efficientnet_model = create_efficientnet(num_classes=8)\n",
                "efficientnet_model.load_weights(\"model_checkpoints/efficientnet_v2m_best_model.weights.h5\")\n",
                "\n",
                "print(\"âœ… Models loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import transforms\n",
                "from PIL import Image\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "class KvasirDataset(Dataset):\n",
                "    def __init__(self, image_paths, labels, transform=None):\n",
                "        self.image_paths = image_paths\n",
                "        self.labels = labels\n",
                "        self.transform = transform\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.image_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
                "        label = self.labels[idx]\n",
                "        if self.transform:\n",
                "            image = self.transform(image)\n",
                "        return image, label\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "# Load dataset\n",
                "def load_dataset_paths(data_dir):\n",
                "    image_paths, labels = [], []\n",
                "    class_names = sorted(os.listdir(data_dir))\n",
                "    class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
                "    \n",
                "    for class_name in class_names:\n",
                "        class_dir = os.path.join(data_dir, class_name)\n",
                "        if not os.path.isdir(class_dir):\n",
                "            continue\n",
                "        for img_name in os.listdir(class_dir):\n",
                "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
                "                image_paths.append(os.path.join(class_dir, img_name))\n",
                "                labels.append(class_to_idx[class_name])\n",
                "    \n",
                "    return image_paths, labels, class_names\n",
                "\n",
                "image_paths, labels, class_names = load_dataset_paths(data_dir)\n",
                "\n",
                "# Split\n",
                "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
                "    image_paths, labels, test_size=0.3, random_state=42, stratify=labels\n",
                ")\n",
                "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
                "    temp_paths, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
                ")\n",
                "\n",
                "train_dataset = KvasirDataset(train_paths, train_labels, transform=transform)\n",
                "val_dataset = KvasirDataset(val_paths, val_labels, transform=transform)\n",
                "test_dataset = KvasirDataset(test_paths, test_labels, transform=transform)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "\n",
                "print(f\"âœ… Data ready: Train={len(train_paths)}, Val={len(val_paths)}, Test={len(test_paths)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Extract Features from Hybrid Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm import tqdm\n",
                "\n",
                "def extract_features(model, efficientnet_model, data_loader, device):\n",
                "    \"\"\"Extract hybrid features for CatBoost\"\"\"\n",
                "    features_list = []\n",
                "    labels_list = []\n",
                "    \n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(data_loader, desc=\"Extracting features\"):\n",
                "            images = images.to(device)\n",
                "            \n",
                "            # Get EfficientNet features\n",
                "            images_np = images.cpu().numpy().transpose(0, 2, 3, 1)\n",
                "            mean = np.array([0.485, 0.456, 0.406])\n",
                "            std = np.array([0.229, 0.224, 0.225])\n",
                "            images_np = images_np * std + mean\n",
                "            images_np = np.clip(images_np * 255, 0, 255)\n",
                "            \n",
                "            eff_logits = efficientnet_model.predict(images_np, verbose=0)\n",
                "            eff_logits = torch.from_numpy(eff_logits).float().to(device)\n",
                "            \n",
                "            # Get hybrid features (concatenated logits)\n",
                "            hybrid_features = model(images, eff_logits, return_features=True)\n",
                "            \n",
                "            features_list.append(hybrid_features.cpu().numpy())\n",
                "            labels_list.append(labels.numpy())\n",
                "    \n",
                "    features = np.vstack(features_list)\n",
                "    labels = np.concatenate(labels_list)\n",
                "    \n",
                "    return features, labels\n",
                "\n",
                "print(\"Extracting training features...\")\n",
                "X_train, y_train = extract_features(hybrid_model, efficientnet_model, train_loader, device)\n",
                "\n",
                "print(\"Extracting validation features...\")\n",
                "X_val, y_val = extract_features(hybrid_model, efficientnet_model, val_loader, device)\n",
                "\n",
                "print(\"Extracting test features...\")\n",
                "X_test, y_test = extract_features(hybrid_model, efficientnet_model, test_loader, device)\n",
                "\n",
                "print(f\"\\nâœ… Features extracted!\")\n",
                "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Optuna TPE Optimization for CatBoost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import optuna\n",
                "from catboost import CatBoostClassifier\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "def objective(trial):\n",
                "    \"\"\"Optuna objective function\"\"\"\n",
                "    \n",
                "    params = {\n",
                "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
                "        'depth': trial.suggest_int('depth', 4, 10),\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
                "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
                "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
                "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.0, 1.0),\n",
                "        'random_strength': trial.suggest_float('random_strength', 0.0, 10.0),\n",
                "        'task_type': 'GPU',\n",
                "        'verbose': False,\n",
                "        'random_seed': 42\n",
                "    }\n",
                "    \n",
                "    model = CatBoostClassifier(**params)\n",
                "    model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=False)\n",
                "    \n",
                "    y_pred = model.predict(X_val)\n",
                "    accuracy = accuracy_score(y_val, y_pred)\n",
                "    \n",
                "    return accuracy\n",
                "\n",
                "print(\"ðŸš€ Starting Optuna TPE optimization...\")\n",
                "print(\"This will run 50 trials to find the best CatBoost hyperparameters\\n\")\n",
                "\n",
                "study = optuna.create_study(\n",
                "    direction='maximize',\n",
                "    sampler=optuna.samplers.TPESampler(seed=42)\n",
                ")\n",
                "\n",
                "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
                "\n",
                "print(\"\\nâœ… Optimization complete!\")\n",
                "print(f\"\\nBest validation accuracy: {study.best_value:.4f}\")\n",
                "print(f\"\\nBest parameters:\")\n",
                "for key, value in study.best_params.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Train Final CatBoost Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train with best parameters\n",
                "best_params = study.best_params\n",
                "best_params['task_type'] = 'GPU'\n",
                "best_params['verbose'] = True\n",
                "best_params['random_seed'] = 42\n",
                "\n",
                "print(\"Training final CatBoost model with best parameters...\\n\")\n",
                "\n",
                "final_model = CatBoostClassifier(**best_params)\n",
                "final_model.fit(\n",
                "    X_train, y_train,\n",
                "    eval_set=(X_val, y_val),\n",
                "    early_stopping_rounds=50,\n",
                "    plot=True\n",
                ")\n",
                "\n",
                "# Save model\n",
                "final_model.save_model('catboost_optimized.cbm')\n",
                "print(\"\\nâœ… Model saved as catboost_optimized.cbm\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Predict\n",
                "y_pred_test = final_model.predict(X_test)\n",
                "\n",
                "# Calculate metrics\n",
                "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
                "\n",
                "print(\"=\"*60)\n",
                "print(\"FINAL TEST RESULTS - OPTIMIZED MODEL\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nðŸŽ¯ Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
                "print(f\"\\nðŸ“Š Improvement over base hybrid: {(test_accuracy - 0.8958)*100:.2f}%\")\n",
                "\n",
                "# Classification report\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"Classification Report:\")\n",
                "print(\"=\"*60)\n",
                "print(classification_report(y_test, y_pred_test, target_names=class_names))\n",
                "\n",
                "# Confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred_test)\n",
                "plt.figure(figsize=(12, 10))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
                "plt.title(f'Confusion Matrix - Optimized CatBoost\\nTest Accuracy: {test_accuracy:.4f}', \n",
                "          fontsize=16, fontweight='bold')\n",
                "plt.ylabel('True Label', fontsize=12)\n",
                "plt.xlabel('Predicted Label', fontsize=12)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.yticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.savefig('catboost_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"\\nâœ… Evaluation complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get feature importance\n",
                "feature_importance = final_model.get_feature_importance()\n",
                "\n",
                "# Plot\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.bar(range(len(feature_importance)), feature_importance)\n",
                "plt.xlabel('Feature Index (0-7: MobileViT, 8-15: EfficientNet)', fontsize=12)\n",
                "plt.ylabel('Importance', fontsize=12)\n",
                "plt.title('CatBoost Feature Importance\\n(Which model contributes more?)', fontsize=14, fontweight='bold')\n",
                "plt.axvline(x=7.5, color='red', linestyle='--', label='MobileViT | EfficientNet')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "mobilevit_importance = feature_importance[:8].sum()\n",
                "efficientnet_importance = feature_importance[8:].sum()\n",
                "\n",
                "print(\"\\nðŸ“Š Model Contribution:\")\n",
                "print(f\"MobileViT features: {mobilevit_importance:.2f}\")\n",
                "print(f\"EfficientNet features: {efficientnet_importance:.2f}\")\n",
                "print(f\"\\nDominant model: {'MobileViT' if mobilevit_importance > efficientnet_importance else 'EfficientNet'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Optuna Optimization History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Get trial history\n",
                "df = study.trials_dataframe()\n",
                "\n",
                "# Plot optimization history\n",
                "plt.figure(figsize=(14, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(df['number'], df['value'], marker='o', alpha=0.6)\n",
                "plt.axhline(y=study.best_value, color='r', linestyle='--', label=f'Best: {study.best_value:.4f}')\n",
                "plt.xlabel('Trial', fontsize=12)\n",
                "plt.ylabel('Validation Accuracy', fontsize=12)\n",
                "plt.title('Optuna Optimization History', fontsize=14, fontweight='bold')\n",
                "plt.legend()\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(df['number'], df['value'].cummax(), marker='o', color='green', alpha=0.6)\n",
                "plt.xlabel('Trial', fontsize=12)\n",
                "plt.ylabel('Best Accuracy So Far', fontsize=12)\n",
                "plt.title('Best Accuracy Progress', fontsize=14, fontweight='bold')\n",
                "plt.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('optuna_history.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "# Save results\n",
                "df.to_csv('optuna_trials.csv', index=False)\n",
                "print(\"\\nâœ… Optimization history saved to optuna_trials.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "# Create summary\n",
                "with open('optimization_summary.txt', 'w') as f:\n",
                "    f.write(\"=\"*60 + \"\\n\")\n",
                "    f.write(\"HYBRID MODEL OPTIMIZATION RESULTS\\n\")\n",
                "    f.write(\"Optuna TPE + CatBoost\\n\")\n",
                "    f.write(\"=\"*60 + \"\\n\\n\")\n",
                "    \n",
                "    f.write(f\"Base Hybrid Model Accuracy: 89.58%\\n\")\n",
                "    f.write(f\"Optimized CatBoost Accuracy: {test_accuracy*100:.2f}%\\n\")\n",
                "    f.write(f\"Improvement: {(test_accuracy - 0.8958)*100:.2f}%\\n\\n\")\n",
                "    \n",
                "    f.write(\"Best Hyperparameters:\\n\")\n",
                "    f.write(\"-\" * 40 + \"\\n\")\n",
                "    for key, value in study.best_params.items():\n",
                "        f.write(f\"{key}: {value}\\n\")\n",
                "    \n",
                "    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n",
                "    f.write(\"Feature Importance:\\n\")\n",
                "    f.write(\"=\"*60 + \"\\n\")\n",
                "    f.write(f\"MobileViT contribution: {mobilevit_importance:.2f}\\n\")\n",
                "    f.write(f\"EfficientNet contribution: {efficientnet_importance:.2f}\\n\")\n",
                "\n",
                "print(\"ðŸ“¥ Downloading results...\\n\")\n",
                "\n",
                "files_to_download = [\n",
                "    'catboost_optimized.cbm',\n",
                "    'catboost_confusion_matrix.png',\n",
                "    'feature_importance.png',\n",
                "    'optuna_history.png',\n",
                "    'optuna_trials.csv',\n",
                "    'optimization_summary.txt'\n",
                "]\n",
                "\n",
                "for filename in files_to_download:\n",
                "    if os.path.exists(filename):\n",
                "        files.download(filename)\n",
                "        print(f\"âœ… Downloaded: {filename}\")\n",
                "\n",
                "print(\"\\nðŸŽ‰ All results downloaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸŽ¯ Summary\n",
                "\n",
                "This notebook:\n",
                "1. âœ… Loaded your trained hybrid model\n",
                "2. âœ… Extracted features from both MobileViT and EfficientNet\n",
                "3. âœ… Used Optuna TPE to optimize CatBoost hyperparameters (50 trials)\n",
                "4. âœ… Trained optimized CatBoost meta-learner\n",
                "5. âœ… Evaluated on test set\n",
                "6. âœ… Analyzed feature importance\n",
                "7. âœ… Downloaded all results\n",
                "\n",
                "### Expected Results:\n",
                "- **Base Hybrid**: 89.58%\n",
                "- **Optimized CatBoost**: 91-93% (expected)\n",
                "\n",
                "### Why This Works:\n",
                "- CatBoost learns optimal combination of hybrid features\n",
                "- Optuna finds best hyperparameters automatically\n",
                "- Meta-learning captures non-linear relationships\n",
                "- GPU acceleration makes it fast!"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}