{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Dual Hybrid Model: Swin-Base + MobileViT\n",
                "\n",
                "## Architecture\n",
                "- **Swin-Base**: Larger Swin Transformer (1024-dim features)\n",
                "- **MobileViT**: Pre-trained on Kvasir (512-dim features)\n",
                "- **Fusion**: Concatenate â†’ 1536-dim â†’ Reduce to 256-dim\n",
                "- **Classifier**: CatBoost (GPU optimized)\n",
                "\n",
                "**Expected Performance**: ~93-94% accuracy (better than Swin-Small)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install packages\n",
                "!pip install -q timm optuna catboost scikit-learn\n",
                "print(\"âœ… Packages installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "weights_path = '/content/drive/MyDrive/TripleHybridModel/mobilevit_kvasir_v2_best_optuna.pth'\n",
                "\n",
                "if os.path.exists(weights_path):\n",
                "    print(f\"âœ… Found MobileViT weights\")\n",
                "else:\n",
                "    print(f\"âŒ Weights not found. Please upload to: MyDrive/TripleHybridModel/\")\n",
                "    weights_path = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torchvision.models as models\n",
                "import timm\n",
                "from torchvision import transforms\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from tqdm.auto import tqdm\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
                "from sklearn.preprocessing import label_binarize\n",
                "import optuna\n",
                "from catboost import CatBoostClassifier\n",
                "import time\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"ðŸŽ® Device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download dataset\n",
                "import zipfile, urllib.request, ssl\n",
                "\n",
                "if not os.path.exists('kvasir-dataset-v2'):\n",
                "    print(\"ðŸ“¥ Downloading Kvasir dataset...\")\n",
                "    ctx = ssl.create_default_context()\n",
                "    ctx.check_hostname = False\n",
                "    ctx.verify_mode = ssl.CERT_NONE\n",
                "    url = \"https://datasets.simula.no/downloads/kvasir/kvasir-dataset-v2.zip\"\n",
                "    with urllib.request.urlopen(url, context=ctx) as response, open('kvasir-dataset-v2.zip', 'wb') as out:\n",
                "        out.write(response.read())\n",
                "    with zipfile.ZipFile('kvasir-dataset-v2.zip', 'r') as zip_ref:\n",
                "        zip_ref.extractall('.')\n",
                "    print(\"âœ… Dataset ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ—ï¸ Dual Hybrid Model: Swin-Base + MobileViT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DualHybridSwinBase(nn.Module):\n",
                "    \"\"\"Swin-Base + MobileViT Hybrid Model\"\"\"\n",
                "    \n",
                "    def __init__(self, mobilevit_weights_path=None):\n",
                "        super().__init__()\n",
                "        \n",
                "        # 1. Swin-Base (larger than Swin-Small)\n",
                "        print(\"Loading Swin-Base...\")\n",
                "        self.swin = models.swin_b(weights=models.Swin_B_Weights.IMAGENET1K_V1)\n",
                "        self.swin.head = nn.Identity()\n",
                "        self.swin_dim = 1024  # Swin-Base output\n",
                "        \n",
                "        # 2. MobileViT\n",
                "        print(\"Loading MobileViT...\")\n",
                "        self.mobilevit = timm.create_model('mobilevitv2_100', pretrained=False, num_classes=8)\n",
                "        if mobilevit_weights_path and os.path.exists(mobilevit_weights_path):\n",
                "            self.mobilevit.load_state_dict(torch.load(mobilevit_weights_path, map_location='cpu'))\n",
                "            print(\"âœ… MobileViT weights loaded\")\n",
                "        self.mobilevit.head.fc = nn.Identity()\n",
                "        self.mobilevit_dim = 512\n",
                "        \n",
                "        # 3. Freeze backbones\n",
                "        for param in self.swin.parameters():\n",
                "            param.requires_grad = False\n",
                "        for param in self.mobilevit.parameters():\n",
                "            param.requires_grad = False\n",
                "        \n",
                "        # 4. Fusion layer (1024 + 512 = 1536 â†’ 256)\n",
                "        combined_dim = self.swin_dim + self.mobilevit_dim  # 1536\n",
                "        self.fusion = nn.Sequential(\n",
                "            nn.Linear(combined_dim, 512),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(512, 256)\n",
                "        )\n",
                "        \n",
                "        print(f\"âœ… Hybrid Model Ready:\")\n",
                "        print(f\"   - Swin-Base: {self.swin_dim}-dim\")\n",
                "        print(f\"   - MobileViT: {self.mobilevit_dim}-dim\")\n",
                "        print(f\"   - Combined: {combined_dim}-dim â†’ Fused: 256-dim\")\n",
                "    \n",
                "    def forward(self, x):\n",
                "        with torch.no_grad():\n",
                "            swin_features = self.swin(x)\n",
                "            mobilevit_features = self.mobilevit(x)\n",
                "            combined = torch.cat([swin_features, mobilevit_features], dim=1)\n",
                "        return self.fusion(combined)\n",
                "\n",
                "print(\"âœ… Model class defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dataset\n",
                "class KvasirDataset(Dataset):\n",
                "    def __init__(self, root_dir, transform=None):\n",
                "        self.root_dir = Path(root_dir)\n",
                "        self.transform = transform\n",
                "        self.samples = []\n",
                "        classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
                "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
                "        for cls in classes:\n",
                "            for img in (self.root_dir / cls).glob('*.jpg'):\n",
                "                self.samples.append((img, self.class_to_idx[cls]))\n",
                "    \n",
                "    def __len__(self): return len(self.samples)\n",
                "    def __getitem__(self, idx):\n",
                "        img, label = self.samples[idx]\n",
                "        return self.transform(Image.open(img).convert('RGB')), label\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "dataset = KvasirDataset('kvasir-dataset-v2', transform=transform)\n",
                "idx = list(range(len(dataset)))\n",
                "labels = [s[1] for s in dataset.samples]\n",
                "tr_idx, temp = train_test_split(idx, test_size=0.3, stratify=labels, random_state=42)\n",
                "val_idx, te_idx = train_test_split(temp, test_size=0.5, stratify=[labels[i] for i in temp], random_state=42)\n",
                "\n",
                "print(f\"ðŸ“Š Dataset: Train={len(tr_idx)}, Val={len(val_idx)}, Test={len(te_idx)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract features\n",
                "model = DualHybridSwinBase(weights_path).to(device).eval()\n",
                "\n",
                "def extract_features(indices, set_name):\n",
                "    loader = DataLoader(torch.utils.data.Subset(dataset, indices), batch_size=32, num_workers=2)\n",
                "    feats, lbls = [], []\n",
                "    start_time = time.time()\n",
                "    for img, lbl in tqdm(loader, desc=f\"Extracting {set_name}\"):\n",
                "        feats.append(model(img.to(device)).cpu().detach().numpy())\n",
                "        lbls.append(lbl.numpy())\n",
                "    extraction_time = time.time() - start_time\n",
                "    return np.vstack(feats), np.concatenate(lbls), extraction_time\n",
                "\n",
                "print(\"ðŸ”¬ Extracting features from Swin-Base + MobileViT...\")\n",
                "X_train, y_train, train_time = extract_features(tr_idx, \"Train\")\n",
                "X_val, y_val, val_time = extract_features(val_idx, \"Val\")\n",
                "X_test, y_test, test_time = extract_features(te_idx, \"Test\")\n",
                "\n",
                "print(f\"\\nâœ… Features: {X_train.shape}\")\n",
                "print(f\"â±ï¸ Extraction time: Train={train_time:.1f}s, Val={val_time:.1f}s, Test={test_time:.1f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train CatBoost\n",
                "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
                "\n",
                "def objective(trial):\n",
                "    params = {\n",
                "        'depth': trial.suggest_int('depth', 4, 10),\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
                "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
                "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
                "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
                "        'task_type': 'GPU',\n",
                "        'verbose': False,\n",
                "        'random_seed': 42\n",
                "    }\n",
                "    clf = CatBoostClassifier(**params)\n",
                "    clf.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=False)\n",
                "    return accuracy_score(y_val, clf.predict(X_val))\n",
                "\n",
                "print(\"ðŸ” Optimizing CatBoost (50 trials)...\")\n",
                "study = optuna.create_study(direction='maximize')\n",
                "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
                "\n",
                "print(f\"\\nðŸ† Best Val Acc: {study.best_value*100:.2f}%\")\n",
                "print(f\"ðŸ”§ Best Params: {study.best_params}\")\n",
                "\n",
                "# Train final model\n",
                "final_params = study.best_params\n",
                "final_params.update({'task_type': 'GPU', 'random_seed': 42})\n",
                "catboost_model = CatBoostClassifier(**final_params)\n",
                "catboost_model.fit(X_train, y_train)\n",
                "\n",
                "print(\"âœ… Model trained!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Calculate All Metrics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_all_metrics(model, X, y, set_name):\n",
                "    y_pred = model.predict(X)\n",
                "    y_pred_proba = model.predict_proba(X)\n",
                "    \n",
                "    acc = accuracy_score(y, y_pred)\n",
                "    prec = precision_score(y, y_pred, average='weighted', zero_division=0)\n",
                "    rec = recall_score(y, y_pred, average='weighted', zero_division=0)\n",
                "    f1 = f1_score(y, y_pred, average='weighted', zero_division=0)\n",
                "    \n",
                "    y_bin = label_binarize(y, classes=range(8))\n",
                "    auroc = roc_auc_score(y_bin, y_pred_proba, average='weighted', multi_class='ovr')\n",
                "    loss = log_loss(y, y_pred_proba)\n",
                "    \n",
                "    cm = confusion_matrix(y, y_pred)\n",
                "    tpr_list, fpr_list = [], []\n",
                "    for i in range(8):\n",
                "        tp = cm[i, i]\n",
                "        fn = cm[i, :].sum() - tp\n",
                "        fp = cm[:, i].sum() - tp\n",
                "        tn = cm.sum() - tp - fn - fp\n",
                "        tpr_list.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
                "        fpr_list.append(fp / (fp + tn) if (fp + tn) > 0 else 0)\n",
                "    \n",
                "    print(f\"\\n{set_name} Metrics:\")\n",
                "    print(f\"  Accuracy: {acc*100:.2f}%\")\n",
                "    print(f\"  Precision: {prec*100:.2f}%\")\n",
                "    print(f\"  Recall: {rec*100:.2f}%\")\n",
                "    print(f\"  F1-Score: {f1*100:.2f}%\")\n",
                "    print(f\"  AUROC: {auroc*100:.2f}%\")\n",
                "    print(f\"  TPR: {np.mean(tpr_list)*100:.2f}%\")\n",
                "    print(f\"  FPR: {np.mean(fpr_list)*100:.2f}%\")\n",
                "    print(f\"  Loss: {loss:.4f}\")\n",
                "    \n",
                "    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1, 'auroc': auroc, \n",
                "            'tpr': np.mean(tpr_list), 'fpr': np.mean(fpr_list), 'loss': loss}\n",
                "\n",
                "train_m = calculate_all_metrics(catboost_model, X_train, y_train, \"Training\")\n",
                "val_m = calculate_all_metrics(catboost_model, X_val, y_val, \"Validation\")\n",
                "test_m = calculate_all_metrics(catboost_model, X_test, y_test, \"Test\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Table\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"SWIN-BASE + MOBILEVIT - COMPLETE RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\n{'Metric':<15} | {'Training':<12} | {'Validation':<12} | {'Test':<12}\")\n",
                "print(\"-\" * 65)\n",
                "print(f\"{'Accuracy':<15} | {train_m['acc']*100:<12.2f} | {val_m['acc']*100:<12.2f} | {test_m['acc']*100:<12.2f}\")\n",
                "print(f\"{'Precision':<15} | {train_m['prec']*100:<12.2f} | {val_m['prec']*100:<12.2f} | {test_m['prec']*100:<12.2f}\")\n",
                "print(f\"{'Recall (TPR)':<15} | {train_m['rec']*100:<12.2f} | {val_m['rec']*100:<12.2f} | {test_m['rec']*100:<12.2f}\")\n",
                "print(f\"{'F1-Score':<15} | {train_m['f1']*100:<12.2f} | {val_m['f1']*100:<12.2f} | {test_m['f1']*100:<12.2f}\")\n",
                "print(f\"{'AUROC':<15} | {train_m['auroc']*100:<12.2f} | {val_m['auroc']*100:<12.2f} | {test_m['auroc']*100:<12.2f}\")\n",
                "print(f\"{'TPR':<15} | {train_m['tpr']*100:<12.2f} | {val_m['tpr']*100:<12.2f} | {test_m['tpr']*100:<12.2f}\")\n",
                "print(f\"{'FPR':<15} | {train_m['fpr']*100:<12.2f} | {val_m['fpr']*100:<12.2f} | {test_m['fpr']*100:<12.2f}\")\n",
                "print(f\"{'Loss':<15} | {train_m['loss']:<12.4f} | {val_m['loss']:<12.4f} | {test_m['loss']:<12.4f}\")\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"âœ… TRAINING COMPLETE\")\n",
                "print(\"=\"*80)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save results\n",
                "catboost_model.save_model('swin_base_hybrid_catboost.cbm')\n",
                "np.savez('swin_base_features.npz', X_train=X_train, y_train=y_train, \n",
                "         X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)\n",
                "\n",
                "# Download\n",
                "from google.colab import files\n",
                "files.download('swin_base_hybrid_catboost.cbm')\n",
                "files.download('swin_base_features.npz')\n",
                "\n",
                "print(\"ðŸ’¾ Files saved and ready for download!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}