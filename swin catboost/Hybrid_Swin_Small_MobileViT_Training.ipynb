{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üöÄ Hybrid Model: Swin Transformer + MobileViT + Gradient Boosting\n",
                "\n",
                "## Architecture Overview\n",
                "**Feature Extraction**: Swin Transformer (Base/Small) + MobileViT ‚Üí **Fusion** ‚Üí **Classifier**: XGBoost/LightGBM/CatBoost\n",
                "\n",
                "### Key Features:\n",
                "- ‚úÖ Dual transformer backbones (Swin + MobileViT)\n",
                "- ‚úÖ Feature fusion layer\n",
                "- ‚úÖ Multiple gradient boosting classifiers\n",
                "- ‚úÖ Optuna optimization with TPE/BOHB samplers\n",
                "- ‚úÖ GPU acceleration support\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìã Step 1: Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
                "!pip install optuna xgboost lightgbm catboost\n",
                "!pip install scikit-learn matplotlib seaborn tqdm\n",
                "!pip install Pillow numpy opencv-python"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify installations\n",
                "import torch\n",
                "import torchvision\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "import catboost as cb\n",
                "import optuna\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "print(f\"CUDA version: {torch.version.cuda}\")\n",
                "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
                "print(f\"XGBoost version: {xgb.__version__}\")\n",
                "print(f\"LightGBM version: {lgb.__version__}\")\n",
                "print(f\"CatBoost version: {cb.__version__}\")\n",
                "print(f\"Optuna version: {optuna.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üì¶ Step 2: Upload Project Files\n",
                "\n",
                "**Upload the following files to Colab:**\n",
                "1. `model.py` - MobileViT architecture\n",
                "2. `dataset.py` - Kvasir dataset loader\n",
                "3. `hybrid_model.py` - Hybrid Swin + MobileViT model\n",
                "4. `gradient_boosting_classifier.py` - GB classifier wrapper\n",
                "5. `train_hybrid_pipeline.py` - Training pipeline\n",
                "6. `mobilevit_kvasir_v2_best_optuna.pth` - Pre-trained MobileViT weights\n",
                "\n",
                "**Option 1: Upload from local machine**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import files\n",
                "\n",
                "print(\"Upload the following files:\")\n",
                "print(\"1. model.py\")\n",
                "print(\"2. dataset.py\")\n",
                "print(\"3. hybrid_model.py\")\n",
                "print(\"4. gradient_boosting_classifier.py\")\n",
                "print(\"5. train_hybrid_pipeline.py\")\n",
                "print(\"6. mobilevit_kvasir_v2_best_optuna.pth\")\n",
                "print(\"\\nClick 'Choose Files' below...\")\n",
                "\n",
                "uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Option 2: Upload from Google Drive**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Copy files from Drive (adjust path as needed)\n",
                "# !cp /content/drive/MyDrive/your_folder/*.py .\n",
                "# !cp /content/drive/MyDrive/your_folder/*.pth ."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Step 3: Download Kvasir Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download and extract Kvasir-V2 dataset\n",
                "!wget https://datasets.simula.no/downloads/kvasir/kvasir-dataset-v2.zip\n",
                "!unzip -q kvasir-dataset-v2.zip\n",
                "!ls -la kvasir-dataset-v2/"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üîç Step 4: Verify Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "required_files = [\n",
                "    'model.py',\n",
                "    'dataset.py',\n",
                "    'hybrid_model.py',\n",
                "    'gradient_boosting_classifier.py',\n",
                "    'train_hybrid_pipeline.py',\n",
                "    'mobilevit_kvasir_v2_best_optuna.pth'\n",
                "]\n",
                "\n",
                "print(\"Checking required files:\")\n",
                "for file in required_files:\n",
                "    exists = os.path.exists(file)\n",
                "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
                "    print(f\"{status} {file}\")\n",
                "\n",
                "print(\"\\nDataset check:\")\n",
                "dataset_exists = os.path.exists('kvasir-dataset-v2/kvasir-dataset-v2')\n",
                "print(f\"{'‚úÖ' if dataset_exists else '‚ùå'} Kvasir dataset\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üß™ Step 5: Quick Test - Hybrid Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test hybrid model initialization\n",
                "from hybrid_model import SwinMobileViTHybrid\n",
                "import torch\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "# Test with Swin-Small\n",
                "print(\"\\n=== Testing Swin-Small + MobileViT ===\")\n",
                "model = SwinMobileViTHybrid(\n",
                "    num_classes=8,\n",
                "    swin_variant='small',\n",
                "    mobilevit_weights_path='mobilevit_kvasir_v2_best_optuna.pth',\n",
                "    freeze_backbones=True\n",
                ").to(device)\n",
                "\n",
                "# Test forward pass\n",
                "dummy_input = torch.randn(2, 3, 224, 224).to(device)\n",
                "features = model.extract_features(dummy_input)\n",
                "\n",
                "print(f\"Input shape: {dummy_input.shape}\")\n",
                "print(f\"Extracted features shape: {features.shape}\")\n",
                "print(f\"Feature dimension: {model.get_feature_dim()}\")\n",
                "\n",
                "# Count parameters\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
                "print(f\"\\nTotal parameters: {total_params:,}\")\n",
                "print(f\"Trainable parameters: {trainable_params:,}\")\n",
                "print(f\"Frozen parameters: {total_params - trainable_params:,}\")\n",
                "\n",
                "print(\"\\n‚úÖ Hybrid model test passed!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üöÄ Step 6: Run Full Training Pipeline\n",
                "\n",
                "### Configuration Options:\n",
                "- **Swin Variant**: `'small'` (lighter, faster) or `'base'` (more powerful)\n",
                "- **Optuna Sampler**: `'tpe'` (Tree-structured Parzen Estimator) or `'bohb'` (Bayesian Optimization HyperBand)\n",
                "- **Optuna Trials**: Number of hyperparameter optimization trials (default: 50)\n",
                "\n",
                "### Training Steps:\n",
                "1. Load pre-trained Swin Transformer and MobileViT\n",
                "2. Extract features from training/validation/test sets\n",
                "3. Optimize XGBoost, LightGBM, and CatBoost with Optuna\n",
                "4. Train best models and evaluate\n",
                "5. Compare results and save best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the complete training pipeline\n",
                "!python train_hybrid_pipeline.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìä Step 7: View Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load and display training summary\n",
                "import json\n",
                "\n",
                "with open('hybrid_results/training_summary.json', 'r') as f:\n",
                "    summary = json.load(f)\n",
                "\n",
                "print(\"=\"*70)\n",
                "print(\"TRAINING SUMMARY\")\n",
                "print(\"=\"*70)\n",
                "\n",
                "print(\"\\nConfiguration:\")\n",
                "for key, value in summary['config'].items():\n",
                "    if key not in ['classifier_types']:\n",
                "        print(f\"  {key}: {value}\")\n",
                "\n",
                "print(\"\\nResults:\")\n",
                "for classifier, result in summary['results'].items():\n",
                "    print(f\"\\n{classifier.upper()}:\")\n",
                "    print(f\"  Validation Accuracy: {result['best_val_accuracy']:.4f}\")\n",
                "    print(f\"  Test Accuracy: {result['metrics']['accuracy']:.4f}\")\n",
                "    print(f\"  Test AUROC: {result['metrics']['auroc']:.4f}\")\n",
                "    print(f\"  Test F1-Score: {result['metrics']['f1_score']:.4f}\")\n",
                "\n",
                "print(f\"\\n{'='*70}\")\n",
                "print(f\"BEST CLASSIFIER: {summary['best_classifier'].upper()}\")\n",
                "print(f\"{'='*70}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üìà Step 8: Visualize Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Extract metrics for visualization\n",
                "classifiers = list(summary['results'].keys())\n",
                "accuracies = [summary['results'][c]['metrics']['accuracy'] for c in classifiers]\n",
                "aurocs = [summary['results'][c]['metrics']['auroc'] for c in classifiers]\n",
                "f1_scores = [summary['results'][c]['metrics']['f1_score'] for c in classifiers]\n",
                "\n",
                "# Create comparison plot\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
                "\n",
                "# Accuracy\n",
                "axes[0].bar(classifiers, accuracies, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
                "axes[0].set_title('Test Accuracy', fontsize=14, fontweight='bold')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].set_ylim([0, 1])\n",
                "for i, v in enumerate(accuracies):\n",
                "    axes[0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "\n",
                "# AUROC\n",
                "axes[1].bar(classifiers, aurocs, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
                "axes[1].set_title('Test AUROC', fontsize=14, fontweight='bold')\n",
                "axes[1].set_ylabel('AUROC')\n",
                "axes[1].set_ylim([0, 1])\n",
                "for i, v in enumerate(aurocs):\n",
                "    axes[1].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "\n",
                "# F1-Score\n",
                "axes[2].bar(classifiers, f1_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
                "axes[2].set_title('Test F1-Score', fontsize=14, fontweight='bold')\n",
                "axes[2].set_ylabel('F1-Score')\n",
                "axes[2].set_ylim([0, 1])\n",
                "for i, v in enumerate(f1_scores):\n",
                "    axes[2].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('hybrid_results/comparison.png', dpi=300, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(\"‚úÖ Visualization saved to hybrid_results/comparison.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üíæ Step 9: Download Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a zip file with all results\n",
                "!zip -r hybrid_results.zip hybrid_results/\n",
                "\n",
                "# Download the zip file\n",
                "from google.colab import files\n",
                "files.download('hybrid_results.zip')\n",
                "\n",
                "print(\"‚úÖ Results downloaded!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üî¨ Step 10: Test Inference (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load best model and test on a sample image\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torchvision import transforms\n",
                "import json\n",
                "\n",
                "# Load best classifier\n",
                "with open('hybrid_results/training_summary.json', 'r') as f:\n",
                "    summary = json.load(f)\n",
                "\n",
                "best_classifier_type = summary['best_classifier']\n",
                "print(f\"Loading best classifier: {best_classifier_type.upper()}\")\n",
                "\n",
                "# Load hybrid model\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "hybrid_model = SwinMobileViTHybrid(\n",
                "    num_classes=8,\n",
                "    swin_variant=summary['config']['swin_variant'],\n",
                "    mobilevit_weights_path=summary['config']['mobilevit_weights'],\n",
                "    freeze_backbones=True\n",
                ").to(device)\n",
                "hybrid_model.eval()\n",
                "\n",
                "# Load gradient boosting classifier\n",
                "from gradient_boosting_classifier import GradientBoostingClassifier\n",
                "gb_classifier = GradientBoostingClassifier(classifier_type=best_classifier_type, num_classes=8)\n",
                "gb_classifier.load(f'hybrid_results/{best_classifier_type}_model')\n",
                "\n",
                "# Define class names\n",
                "class_names = ['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', \n",
                "               'normal-cecum', 'normal-pylorus', 'normal-z-line', \n",
                "               'polyps', 'ulcerative-colitis']\n",
                "\n",
                "# Inference function\n",
                "def predict_image(image_path):\n",
                "    # Load and preprocess image\n",
                "    transform = transforms.Compose([\n",
                "        transforms.Resize((224, 224)),\n",
                "        transforms.ToTensor(),\n",
                "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "    ])\n",
                "    \n",
                "    image = Image.open(image_path).convert('RGB')\n",
                "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
                "    \n",
                "    # Extract features\n",
                "    with torch.no_grad():\n",
                "        features = hybrid_model.extract_features(image_tensor)\n",
                "        features_np = features.cpu().numpy()\n",
                "    \n",
                "    # Predict\n",
                "    prediction = gb_classifier.model.predict(features_np)[0]\n",
                "    probabilities = gb_classifier.model.predict_proba(features_np)[0]\n",
                "    \n",
                "    # Display results\n",
                "    plt.figure(figsize=(12, 4))\n",
                "    \n",
                "    # Show image\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.imshow(image)\n",
                "    plt.title(f'Predicted: {class_names[prediction]}', fontsize=12, fontweight='bold')\n",
                "    plt.axis('off')\n",
                "    \n",
                "    # Show probabilities\n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.barh(class_names, probabilities)\n",
                "    plt.xlabel('Probability')\n",
                "    plt.title('Class Probabilities', fontsize=12, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "    \n",
                "    return class_names[prediction], probabilities\n",
                "\n",
                "# Test on a sample image from the dataset\n",
                "import glob\n",
                "sample_images = glob.glob('kvasir-dataset-v2/kvasir-dataset-v2/polyps/*.jpg')[:1]\n",
                "if sample_images:\n",
                "    print(f\"Testing on: {sample_images[0]}\")\n",
                "    predicted_class, probs = predict_image(sample_images[0])\n",
                "    print(f\"\\nPredicted class: {predicted_class}\")\n",
                "    print(f\"Confidence: {probs.max():.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## üéØ Summary\n",
                "\n",
                "### What We Built:\n",
                "1. ‚úÖ **Hybrid Feature Extractor**: Swin Transformer + MobileViT\n",
                "2. ‚úÖ **Feature Fusion**: Concatenation + Dense layers\n",
                "3. ‚úÖ **Multiple Classifiers**: XGBoost, LightGBM, CatBoost\n",
                "4. ‚úÖ **Hyperparameter Optimization**: Optuna with TPE/BOHB\n",
                "5. ‚úÖ **Complete Pipeline**: Training, evaluation, and inference\n",
                "\n",
                "### Expected Performance:\n",
                "- **Accuracy**: 85-95% (depending on configuration)\n",
                "- **AUROC**: 95-99%\n",
                "- **Training Time**: ~2-4 hours on Colab GPU\n",
                "\n",
                "### Next Steps:\n",
                "- Fine-tune the fusion layer\n",
                "- Try different Swin variants (Base vs Small)\n",
                "- Experiment with different feature fusion strategies\n",
                "- Deploy the best model for production use\n",
                "\n",
                "---\n",
                "**Created for Google Colab with GPU support** üöÄ"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}