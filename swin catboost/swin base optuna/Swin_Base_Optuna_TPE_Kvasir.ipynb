{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸš€ Swin-Base + MobileViT (Kvasir) with Optuna TPE\n",
                "\n",
                "## Architecture\n",
                "- **Swin-Base**: 1024-dim features (ImageNet pretrained)\n",
                "- **MobileViT**: 384-dim features (**Kvasir pretrained** - custom architecture)\n",
                "- **Fusion**: 1024 + 384 = 1408-dim -> 256-dim\n",
                "- **Classifier**: CatBoost with Optuna TPE optimization\n",
                "\n",
                "## Expected Results\n",
                "- **Accuracy**: ~88-90% (with Kvasir MobileViT)\n",
                "- **AUROC**: ~98-99%\n",
                "- **Training Time**: ~45-50 minutes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q optuna catboost scikit-learn\n",
                "print(\"âœ… Packages installed\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import os\n",
                "weights_path = '/content/drive/MyDrive/TripleHybridModel/mobilevit_kvasir_v2_best_optuna.pth'\n",
                "\n",
                "if os.path.exists(weights_path):\n",
                "    print(f\"âœ… Found MobileViT Kvasir weights\")\n",
                "else:\n",
                "    print(f\"âŒ Weights not found\")\n",
                "    weights_path = None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torchvision.models as models\n",
                "from torchvision import transforms\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from PIL import Image\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from tqdm.auto import tqdm\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, log_loss\n",
                "from sklearn.preprocessing import label_binarize\n",
                "import optuna\n",
                "from catboost import CatBoostClassifier\n",
                "import time, json\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f\"ðŸŽ® Device: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not os.path.exists('kvasir-dataset-v2'):\n",
                "    !wget --no-check-certificate https://datasets.simula.no/downloads/kvasir/kvasir-dataset-v2.zip\n",
                "    !unzip -q kvasir-dataset-v2.zip\n",
                "    print(\"âœ… Dataset ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ—ï¸ Custom MobileViT (same as Swin-Small notebook)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# [Copy the exact same MobileViT code from Swin-Small notebook]\n",
                "# Helper functions\n",
                "def conv_1x1_bn(inp, oup):\n",
                "    return nn.Sequential(nn.Conv2d(inp, oup, 1, 1, 0, bias=False), nn.BatchNorm2d(oup), nn.Hardswish())\n",
                "\n",
                "def conv_nxn_bn(inp, oup, kernal_size=3, stride=1):\n",
                "    return nn.Sequential(nn.Conv2d(inp, oup, kernal_size, stride, 1, bias=False), nn.BatchNorm2d(oup), nn.Hardswish())\n",
                "\n",
                "class PreNorm(nn.Module):\n",
                "    def __init__(self, dim, fn):\n",
                "        super().__init__()\n",
                "        self.norm = nn.LayerNorm(dim)\n",
                "        self.fn = fn\n",
                "    def forward(self, x, *args, **kwargs):\n",
                "        return self.fn(self.norm(x), *args, **kwargs)\n",
                "\n",
                "class FeedForward(nn.Module):\n",
                "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(nn.Linear(dim, hidden_dim), nn.Hardswish(), nn.Dropout(dropout), nn.Linear(hidden_dim, dim), nn.Dropout(dropout))\n",
                "    def forward(self, x):\n",
                "        return self.net(x)\n",
                "\n",
                "class Attention(nn.Module):\n",
                "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
                "        super().__init__()\n",
                "        self.inner_dim = dim_head * heads\n",
                "        self.heads, self.scale = heads, dim_head ** -0.5\n",
                "        self.attend = nn.Softmax(dim=-1)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        self.to_qkv = nn.Linear(dim, self.inner_dim * 3, bias=False)\n",
                "        self.to_out = nn.Sequential(nn.Linear(self.inner_dim, dim), nn.Dropout(dropout)) if not (heads == 1 and dim_head == dim) else nn.Identity()\n",
                "    def forward(self, x):\n",
                "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
                "        q, k, v = map(lambda t: t.reshape(t.shape[0], t.shape[1], self.heads, t.shape[2] // self.heads).transpose(1, 2), qkv)\n",
                "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
                "        attn = self.dropout(self.attend(dots))\n",
                "        out = torch.matmul(attn, v).transpose(1, 2).reshape(out.shape[0], out.shape[1], self.inner_dim)\n",
                "        return self.to_out(out)\n",
                "\n",
                "class TransformerBlock(nn.Module):\n",
                "    def __init__(self, dim, heads, dim_head, mlp_dim, dropout=0.):\n",
                "        super().__init__()\n",
                "        self.attn = PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout))\n",
                "        self.ff = PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
                "    def forward(self, x):\n",
                "        return x + self.ff(x + self.attn(x))\n",
                "\n",
                "class MobileNetV2Block(nn.Module):\n",
                "    def __init__(self, inp, oup, stride, expansion):\n",
                "        super().__init__()\n",
                "        self.stride, hidden_dim = stride, int(round(inp * expansion))\n",
                "        self.use_res_connect = self.stride == 1 and inp == oup\n",
                "        layers = [nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False), nn.BatchNorm2d(hidden_dim), nn.Hardswish()] if expansion != 1 else []\n",
                "        layers.extend([nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False), nn.BatchNorm2d(hidden_dim), nn.Hardswish(), nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False), nn.BatchNorm2d(oup)])\n",
                "        self.conv = nn.Sequential(*layers)\n",
                "    def forward(self, x):\n",
                "        return x + self.conv(x) if self.use_res_connect else self.conv(x)\n",
                "\n",
                "class MobileViTBlock(nn.Module):\n",
                "    def __init__(self, dim, depth, channel, kernal_size, patch_size, mlp_dim, dropout=0.):\n",
                "        super().__init__()\n",
                "        self.ph, self.pw = patch_size\n",
                "        self.conv1 = conv_nxn_bn(channel, channel, kernal_size)\n",
                "        self.conv2 = conv_1x1_bn(channel, dim)\n",
                "        self.transformer = nn.Sequential(*[TransformerBlock(dim, 4, 8, mlp_dim, dropout) for _ in range(depth)])\n",
                "        self.conv3 = conv_1x1_bn(dim, channel)\n",
                "        self.conv4 = conv_nxn_bn(2 * channel, channel, kernal_size)\n",
                "    def forward(self, x):\n",
                "        y = x.clone()\n",
                "        x = self.conv2(self.conv1(x))\n",
                "        B, D, H, W = x.shape\n",
                "        pad_h, pad_w = (self.ph - (H % self.ph)) % self.ph, (self.pw - (W % self.pw)) % self.pw\n",
                "        if pad_h > 0 or pad_w > 0:\n",
                "            x = F.pad(x, (0, pad_w, 0, pad_h))\n",
                "            H, W = H + pad_h, W + pad_w\n",
                "        h_split, w_split = H // self.ph, W // self.pw\n",
                "        x = x.reshape(B, D, h_split, self.ph, w_split, self.pw).permute(0, 2, 4, 3, 5, 1).contiguous().view(B * h_split * w_split, self.ph * self.pw, D)\n",
                "        x = self.transformer(x).view(B, h_split, w_split, self.ph, self.pw, D).permute(0, 5, 1, 3, 2, 4).contiguous().view(B, D, H, W)\n",
                "        if pad_h > 0 or pad_w > 0:\n",
                "            x = x[:, :, :H-pad_h, :W-pad_w]\n",
                "        return self.conv4(torch.cat((self.conv3(x), y), 1))\n",
                "\n",
                "class MobileViT(nn.Module):\n",
                "    def __init__(self, image_size, num_classes, dims, channels, depths, patch_size=2, mlp_dim_ratio=2):\n",
                "        super().__init__()\n",
                "        self.conv1 = conv_nxn_bn(3, channels[0], kernal_size=3, stride=2)\n",
                "        self.stem = nn.ModuleList([MobileNetV2Block(channels[i], channels[i+1], stride=2 if i in [1,3] else 1, expansion=4) for i in range(4)])\n",
                "        self.mobilevit_blocks = nn.ModuleList()\n",
                "        in_channel = channels[4]\n",
                "        for i in range(len(dims)):\n",
                "            self.mobilevit_blocks.append(MobileViTBlock(dims[i], depths[i], in_channel, 3, (patch_size, patch_size), dims[i] * mlp_dim_ratio))\n",
                "            if i < len(dims) - 1:\n",
                "                self.mobilevit_blocks.append(MobileNetV2Block(in_channel, channels[i+5], stride=2, expansion=4))\n",
                "                in_channel = channels[i+5]\n",
                "        self.conv2 = conv_1x1_bn(in_channel, dims[-1])\n",
                "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
                "        self.fc = nn.Linear(dims[-1], num_classes)\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        for block in self.stem:\n",
                "            x = block(x)\n",
                "        for block in self.mobilevit_blocks:\n",
                "            x = block(x)\n",
                "        return self.fc(self.pool(self.conv2(x)).flatten(1))\n",
                "\n",
                "print(\"âœ… MobileViT defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SwinBaseMobileViTHybrid(nn.Module):\n",
                "    def __init__(self, mobilevit_weights_path=None):\n",
                "        super().__init__()\n",
                "        print(\"Loading Swin-Base...\")\n",
                "        self.swin = models.swin_b(weights=models.Swin_B_Weights.IMAGENET1K_V1)\n",
                "        self.swin.head = nn.Identity()\n",
                "        self.swin_dim = 1024\n",
                "        \n",
                "        print(\"Loading Custom MobileViT...\")\n",
                "        self.mobilevit = MobileViT(image_size=224, num_classes=8, dims=[96, 192, 384], channels=[16, 32, 64, 128, 160, 192, 256, 320, 384, 512], depths=[2, 2, 2])\n",
                "        if mobilevit_weights_path and os.path.exists(mobilevit_weights_path):\n",
                "            self.mobilevit.load_state_dict(torch.load(mobilevit_weights_path, map_location='cpu'))\n",
                "            print(\"âœ… MobileViT Kvasir weights loaded!\")\n",
                "        self.mobilevit.fc = nn.Identity()\n",
                "        self.mobilevit_dim = 384\n",
                "        \n",
                "        for param in self.swin.parameters():\n",
                "            param.requires_grad = False\n",
                "        for param in self.mobilevit.parameters():\n",
                "            param.requires_grad = False\n",
                "        \n",
                "        combined_dim = self.swin_dim + self.mobilevit_dim\n",
                "        self.fusion = nn.Sequential(nn.Linear(combined_dim, 512), nn.ReLU(), nn.Dropout(0.3), nn.Linear(512, 256))\n",
                "        print(f\"âœ… Hybrid: {self.swin_dim} + {self.mobilevit_dim} = {combined_dim} -> 256\")\n",
                "    \n",
                "    def forward(self, x):\n",
                "        with torch.no_grad():\n",
                "            return self.fusion(torch.cat([self.swin(x), self.mobilevit(x)], dim=1))\n",
                "\n",
                "print(\"âœ… Hybrid model defined\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class KvasirDataset(Dataset):\n",
                "    def __init__(self, root_dir, transform=None):\n",
                "        self.root_dir = Path(root_dir)\n",
                "        self.transform = transform\n",
                "        self.samples = []\n",
                "        classes = sorted([d.name for d in self.root_dir.iterdir() if d.is_dir()])\n",
                "        self.class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
                "        for cls in classes:\n",
                "            for img in (self.root_dir / cls).glob('*.jpg'):\n",
                "                self.samples.append((img, self.class_to_idx[cls]))\n",
                "    def __len__(self): return len(self.samples)\n",
                "    def __getitem__(self, idx):\n",
                "        img, label = self.samples[idx]\n",
                "        return self.transform(Image.open(img).convert('RGB')), label\n",
                "\n",
                "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
                "dataset_path = 'kvasir-dataset-v2/kvasir-dataset-v2' if os.path.exists('kvasir-dataset-v2/kvasir-dataset-v2') else 'kvasir-dataset-v2'\n",
                "dataset = KvasirDataset(dataset_path, transform=transform)\n",
                "idx = list(range(len(dataset)))\n",
                "labels = [s[1] for s in dataset.samples]\n",
                "tr_idx, temp = train_test_split(idx, test_size=0.3, stratify=labels, random_state=42)\n",
                "val_idx, te_idx = train_test_split(temp, test_size=0.5, stratify=[labels[i] for i in temp], random_state=42)\n",
                "print(f\"ðŸ“Š Dataset: Train={len(tr_idx)}, Val={len(val_idx)}, Test={len(te_idx)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = SwinBaseMobileViTHybrid(weights_path).to(device).eval()\n",
                "\n",
                "def extract_features(indices, set_name):\n",
                "    loader = DataLoader(torch.utils.data.Subset(dataset, indices), batch_size=32, num_workers=2)\n",
                "    feats, lbls = [], []\n",
                "    start_time = time.time()\n",
                "    for img, lbl in tqdm(loader, desc=f\"Extracting {set_name}\"):\n",
                "        feats.append(model(img.to(device)).cpu().detach().numpy())\n",
                "        lbls.append(lbl.numpy())\n",
                "    return np.vstack(feats), np.concatenate(lbls), time.time() - start_time\n",
                "\n",
                "print(\"ðŸ”¬ Extracting features...\")\n",
                "X_train, y_train, train_time = extract_features(tr_idx, \"Train\")\n",
                "X_val, y_val, val_time = extract_features(val_idx, \"Val\")\n",
                "X_test, y_test, test_time = extract_features(te_idx, \"Test\")\n",
                "print(f\"\\nâœ… Features: {X_train.shape}\")\n",
                "print(f\"â±ï¸ Time: Train={train_time:.1f}s, Val={val_time:.1f}s, Test={test_time:.1f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
                "\n",
                "def objective(trial):\n",
                "    params = {'depth': trial.suggest_int('depth', 4, 10), 'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True), 'iterations': trial.suggest_int('iterations', 100, 1000), 'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10), 'border_count': trial.suggest_int('border_count', 32, 255), 'task_type': 'GPU', 'verbose': False, 'random_seed': 42}\n",
                "    clf = CatBoostClassifier(**params)\n",
                "    clf.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50, verbose=False)\n",
                "    return accuracy_score(y_val, clf.predict(X_val))\n",
                "\n",
                "print(\"ðŸ” Optuna TPE (50 trials)...\")\n",
                "opt_start = time.time()\n",
                "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
                "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
                "opt_time = time.time() - opt_start\n",
                "print(f\"\\nðŸ† Best: {study.best_value*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_params = study.best_params\n",
                "final_params.update({'task_type': 'GPU', 'random_seed': 42, 'verbose': True})\n",
                "final_model = CatBoostClassifier(**final_params)\n",
                "train_start = time.time()\n",
                "final_model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=50)\n",
                "train_time_final = time.time() - train_start"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calc_metrics(model, X, y):\n",
                "    start = time.time()\n",
                "    y_pred, y_prob = model.predict(X), model.predict_proba(X)\n",
                "    inf_time = time.time() - start\n",
                "    y_bin = label_binarize(y, classes=range(8))\n",
                "    cm = confusion_matrix(y, y_pred)\n",
                "    tpr_list, fpr_list = [], []\n",
                "    for i in range(8):\n",
                "        tp, fn, fp = cm[i, i], cm[i, :].sum() - cm[i, i], cm[:, i].sum() - cm[i, i]\n",
                "        tn = cm.sum() - tp - fn - fp\n",
                "        tpr_list.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
                "        fpr_list.append(fp / (fp + tn) if (fp + tn) > 0 else 0)\n",
                "    return {'accuracy': accuracy_score(y, y_pred), 'precision': precision_score(y, y_pred, average='weighted', zero_division=0), 'recall': recall_score(y, y_pred, average='weighted', zero_division=0), 'f1_score': f1_score(y, y_pred, average='weighted', zero_division=0), 'auroc': roc_auc_score(y_bin, y_prob, average='weighted', multi_class='ovr'), 'tpr': np.mean(tpr_list), 'fpr': np.mean(fpr_list), 'loss': log_loss(y, y_prob), 'time': inf_time}\n",
                "\n",
                "train_m = calc_metrics(final_model, X_train, y_train)\n",
                "val_m = calc_metrics(final_model, X_val, y_val)\n",
                "test_m = calc_metrics(final_model, X_test, y_test)\n",
                "print(f\"\\nTest: {test_m['accuracy']*100:.2f}% | AUROC: {test_m['auroc']*100:.2f}%\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_model.save_model('swin_base_kvasir_optuna.cbm')\n",
                "np.savez('swin_base_kvasir_features.npz', X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test)\n",
                "results = {'architecture': 'Swin-Base + MobileViT (Kvasir)', 'optimization': 'Optuna TPE', 'n_trials': 50, 'best_params': study.best_params, 'best_val_accuracy': study.best_value, 'training_metrics': train_m, 'validation_metrics': val_m, 'test_metrics': test_m, 'timing': {'feature_extraction': {'train': train_time, 'val': val_time, 'test': test_time}, 'optimization': opt_time, 'final_training': train_time_final}}\n",
                "with open('swin_base_kvasir_optuna_results.json', 'w') as f:\n",
                "    json.dump(results, f, indent=2, default=float)\n",
                "\n",
                "from google.colab import files\n",
                "files.download('swin_base_kvasir_optuna.cbm')\n",
                "files.download('swin_base_kvasir_features.npz')\n",
                "files.download('swin_base_kvasir_optuna_results.json')\n",
                "print(\"âœ… Done!\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}